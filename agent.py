import os
import json
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import HumanMessage

# ====================================
# 1ï¸âƒ£ DeepSeek API é…ç½®
# ====================================
os.environ["OPENAI_API_KEY"] = "your_deepseek_api_key_here"#ä¹Ÿå¯ä»¥åˆ‡æ¢å…¶ä»–æ¨¡å‹
os.environ["OPENAI_BASE_URL"] = "https://api.deepseek.com"

# ====================================
# 2ï¸âƒ£ åŠ è½½å‘é‡åº“
# ====================================
EMBED_MODEL = "BAAI/bge-large-zh"
INDEX_PATH = "longzu13_index"

embeddings = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL,
    encode_kwargs={"normalize_embeddings": True}  # âœ… å¯ç”¨å½’ä¸€åŒ–
)
vectorstore = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
retriever = vectorstore.as_retriever(search_kwargs={"k": 8})

# ====================================
# 3ï¸âƒ£ å…¨å±€å˜é‡ï¼šåŸå§‹é—®é¢˜
# ====================================
GLOBAL_QUESTION = ""


# ====================================
# 4ï¸âƒ£ æ ¹æ® chunk_index è·å–åŸæ–‡
# ====================================
def fetch_by_meta(text: str) -> str:
    """
    è¾“å…¥æ ¼å¼ï¼š"1234" æˆ– 1234
    æ ¹æ® chunk_index è¿”å›åŸæ–‡å†…å®¹ã€‚
    """
    try:
        clean_text = text.strip().strip('"').strip("'")
        chunk_index = int(clean_text)
    except Exception:
        return f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºçº¯æ•°å­— chunk_indexï¼Œä¾‹å¦‚ '1234'ï¼ˆæ”¶åˆ°: {text}ï¼‰"

    for doc in vectorstore.docstore._dict.values():
        meta = doc.metadata
        if int(meta.get("chunk_index", -1)) == chunk_index:
            chapter_idx = meta.get("chapter_index", -1)
            offset = meta.get("offset_in_chapter", -1)
            return f"[ç¬¬{chapter_idx}ç«  ç¬¬{offset}æ®µ | chunk_index={chunk_index}]\n{doc.page_content.strip()}"

    return f"âŒ æœªæ‰¾åˆ° chunk_index={chunk_index} å¯¹åº”çš„å†…å®¹"


# ====================================
# 5ï¸âƒ£ æ£€ç´¢ + ç›¸å…³æ€§åˆ¤æ–­
# ====================================
def search_and_judge(query_text: str) -> str:
    """
    æ ¹æ® llm ç”Ÿæˆçš„å…³é”®è¯æ‰§è¡Œæ£€ç´¢ï¼Œ
    ä½¿ç”¨å…¨å±€åŸé—®é¢˜ (GLOBAL_QUESTION) åˆ¤æ–­æ˜¯å¦ç›¸å…³ã€‚
    è‹¥ç›¸å…³è¿”å›ç»“æ„åŒ–ç»“æœï¼ˆchunk_indexã€ç« èŠ‚ç´¢å¼•ã€åç§»ã€æ‘˜è¦ï¼‰ï¼Œå¦åˆ™è¿”å›â€œæ— æ•ˆâ€ã€‚
    """
    global GLOBAL_QUESTION
    original_question = GLOBAL_QUESTION or "(æ— )"

    # Step 1ï¸âƒ£ ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆå–å‰15ï¼‰
    docs_and_scores = vectorstore.similarity_search_with_score(query_text, k=15)
    # å› ä¸º BGE å‘é‡ç»è¿‡å½’ä¸€åŒ–ï¼Œç›¸ä¼¼åº¦è¶Šå¤§è¶Šç›¸ä¼¼
    docs_and_scores = sorted(docs_and_scores, key=lambda x: x[1], reverse=True)
    top_docs = docs_and_scores[:5]

    if not top_docs:
        return "æ— æ•ˆ"

    # Step 2ï¸âƒ£ æ•´ç†æ–‡æœ¬ä¸å…ƒä¿¡æ¯
    snippets = []
    for doc, score in top_docs:
        meta = doc.metadata
        snippets.append({
            "chunk_index": int(meta.get("chunk_index")),
            "chapter_index": int(meta.get("chapter_index")),
            "offset_in_chapter": int(meta.get("offset_in_chapter")),
            "score": round(float(score), 4),
            "text": doc.page_content.strip()
        })

    context_json = json.dumps(snippets, ensure_ascii=False, indent=2)

    # Step 3ï¸âƒ£ è®© LLM åˆ¤æ–­ + ç”Ÿæˆæ‘˜è¦
    llm_judge = ChatOpenAI(
        model="deepseek-chat",
        temperature=0.2,
        openai_api_base="https://api.deepseek.com",
        openai_api_key=os.environ["OPENAI_API_KEY"],
    )

    prompt = f"""
ä½ æ˜¯ä¸€åå°è¯´å†…å®¹åˆ†æåŠ©æ‰‹ã€‚
ç”¨æˆ·çš„åŸé—®é¢˜æ˜¯ï¼šã€Œ{original_question}ã€
å…³é”®è¯æ£€ç´¢ä¸ºï¼šã€Œ{query_text}ã€

ä»¥ä¸‹æ˜¯æ ¹æ®å…³é”®è¯æ£€ç´¢åˆ°çš„å°è¯´ç‰‡æ®µï¼ˆå®Œæ•´æ–‡æœ¬ + å…ƒä¿¡æ¯ï¼‰ã€‚

### ä»»åŠ¡è¦æ±‚ï¼š
1. å¦‚æœæ‰€æœ‰ç‰‡æ®µéƒ½æ— å…³ï¼Œè¯·è¾“å‡º â€œæ— æ•ˆâ€ã€‚
2. å¦‚æœéƒ¨åˆ†ç‰‡æ®µç›¸å…³ï¼Œè¯·é€‰æ‹©æœ€ç›¸å…³çš„ 1~2 ä¸ªã€‚
3. æ¯ä¸ªé€‰ä¸­ç‰‡æ®µç”Ÿæˆä¸€ä¸ªç®€çŸ­æ‘˜è¦ï¼ˆâ‰¤100å­—ï¼‰ï¼Œè¯´æ˜å®ƒä¸ç”¨æˆ·é—®é¢˜çš„å…³ç³»ã€‚
4. è¾“å‡ºä¸¥æ ¼ä¸º JSON æ•°ç»„ï¼Œå­—æ®µå¦‚ä¸‹ï¼š
   - chunk_index (æ•°å­—, æ¥è‡ª metadata)
   - chapter_index (æ•°å­—, æ¥è‡ª metadata)
   - offset_in_chapter (æ•°å­—, æ¥è‡ª metadata)
   - summary (æ‘˜è¦æ–‡æœ¬)

å°è¯´ç‰‡æ®µå¦‚ä¸‹ (JSON æ•°æ®)ï¼š
{context_json}

è¯·ä¸¥æ ¼è¾“å‡ºç¬¦åˆ JSON è¯­æ³•çš„ç»“æœï¼š
"""

    resp = llm_judge.invoke([HumanMessage(content=prompt)])
    return resp.content.strip()


# ====================================
# 6ï¸âƒ£ æ³¨å†Œå·¥å…·
# ====================================
tools = [
    Tool(
        name="NovelSearch",
        func=search_and_judge,
        description=(
            "æ ¹æ®å…³é”®è¯æ£€ç´¢å°è¯´ç‰‡æ®µå¹¶åˆ¤æ–­æ˜¯å¦å›ç­”äº†ç”¨æˆ·é—®é¢˜ã€‚"
            "è¾“å…¥å…³é”®è¯å¯ä»¥æ˜¯å¥å­ï¼Œè¯¦ç»†ä¸€ç‚¹ï¼Œè¿”å›çš„æ˜¯JSONç»“æ„ï¼ŒåŒ…å«chunk_indexã€chapter_indexã€offset_in_chapterã€æ‘˜è¦ã€‚"
        ),
    ),
    Tool(
        name="FetchByMeta",
        func=fetch_by_meta,
        description="æ ¹æ® chunk_index è·å–å°è¯´åŸæ–‡ï¼Œè¾“å…¥æ ¼å¼ä¸º'1234'ã€‚",
    )
]

# ====================================
# 7ï¸âƒ£ åˆ›å»º DeepSeek Agent
# ====================================
llm_agent = ChatOpenAI(
    model="deepseek-chat",
    temperature=0.4,
    openai_api_base="https://api.deepseek.com",
    openai_api_key=os.environ["OPENAI_API_KEY"],
)

agent = initialize_agent(
    tools=tools,
    llm=llm_agent,
    agent_type="zero-shot-react-description",
    verbose=True,
    handle_parsing_errors=True,
)

# ====================================
# 8ï¸âƒ£ ç”¨æˆ·æ¥å£
# ====================================
def ask_novel_question(question: str):
    global GLOBAL_QUESTION
    GLOBAL_QUESTION = question
    return agent.invoke(
        f"è¯·æ ¹æ®å°è¯´å†…å®¹å›ç­”ï¼š{question}ã€‚"
        f"å¦‚æœ‰éœ€è¦ï¼Œå¯è°ƒç”¨ NovelSearch æˆ– FetchByMeta å·¥å…·ã€‚"
        f"NovelSearch å·¥å…·è¿”å›çš„ç»“æœä¸­å«æœ‰chunk_index ï¼Œchunk_indexæŒ‰å°è¯´é¡ºåºæ’åˆ—ï¼Œå¦‚æœæ‰¾åˆ°ç›¸å…³çš„chunk_index,è¯·è‡ªåŠ¨è°ƒç”¨ FetchByMeta è·å–å®Œæ•´å†…å®¹ã€‚"
        f"å¤šåˆ©ç”¨chunk_indexä¸­è•´å«çš„æ—¶é—´ã€‚åŠ å‡chunk_indexè·å–å…¶ç›¸é‚»çš„åŸæ–‡"
    )


# ====================================
# 9ï¸âƒ£ æµ‹è¯•
# ====================================
if __name__ == "__main__":
    q = "è·¯æ˜éåœ¨ç”µå½±é™¢è¢«èµµå­Ÿåæˆè€ï¼Œè¯ºè¯ºæ•‘åœºè¿™ä¸ªç‰‡æ®µçš„å…·ä½“ç»†èŠ‚ï¼Ÿ"
    print("\nğŸ§  ç”¨æˆ·é—®é¢˜ï¼š", q)
    ans = ask_novel_question(q)
    print("\nâœ… æœ€ç»ˆå›ç­”ï¼š", ans)
